{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ca9fb6",
   "metadata": {},
   "source": [
    "# Datensatz splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d6251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc75e87",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Einstellungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d42987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-Verhältnis einstellen\n",
    "SPLIT_RATIOS = {\n",
    "    'train': 0.7,      # 70% für Training\n",
    "    'val': 0.2,        # 20% für Validierung\n",
    "    'test': 0.1        # 10% für Test\n",
    "}\n",
    "\n",
    "AUG_IMAGES_DIR = r\"C:\\Users\\jonni\\OneDrive\\Dokumente\\GitHub\\Chairlift_Gefahrenerkennung\\01_Data_Jon\\Augmented\\Images\"\n",
    "AUG_LABELS_DIR = r\"C:\\Users\\jonni\\OneDrive\\Dokumente\\GitHub\\Chairlift_Gefahrenerkennung\\01_Data_Jon\\Augmented\\Labels\"\n",
    "\n",
    "# (Optional: Anpassen/ergänzen)\n",
    "CLASS_NAMES = [\n",
    "    'KLEBER', 'EDDING', 'TACKER'  # Ersetze/ergänze mit deinen tatsächlichen Klassen\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf5c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Name des Quellordners der Bilder extrahieren\n",
    "SOURCE_DIR = os.path.basename(AUG_IMAGES_DIR)\n",
    "\n",
    "# Verzeichnis in dem das Bild Verzeichnis liegt\n",
    "SOURCE_DIR_PATH = os.path.dirname(AUG_IMAGES_DIR)\n",
    "\n",
    "# Zielverzeichnis für die Splits ist der gleiche wie das Quellverzeichnis.\n",
    "# Der Name des Quellverzeichnisses wird als Zielverzeichnis verwendet und mit \"_split\" ergänzt.\n",
    "TARGET_DIR = os.path.join(SOURCE_DIR_PATH, f\"{SOURCE_DIR}_split\")\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "# Zielverzeichnis für die Splits\n",
    "DATASET_ROOT = os.path.join(TARGET_DIR, SOURCE_DIR)\n",
    "os.makedirs(DATASET_ROOT, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729306ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Split Vorgang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c737f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensatz gesplittet: 315 train, 90 val, 45 test\n",
      "dataset.yaml erstellt!\n",
      "Gespeichert in: C:\\Users\\jonni\\OneDrive\\Dokumente\\GitHub\\Chairlift_Gefahrenerkennung\\01_Data_Jon\\Augmented\\Images_split\\Images\\dataset.yaml\n"
     ]
    }
   ],
   "source": [
    "# Split-Verzeichnisse erstellen\n",
    "def make_dirs():\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        os.makedirs(os.path.join(DATASET_ROOT, split, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(DATASET_ROOT, split, 'labels'), exist_ok=True)\n",
    "\n",
    "make_dirs()\n",
    "\n",
    "# Alle Bilder finden (nur augmentierte verwenden!)\n",
    "all_images = sorted(glob(os.path.join(AUG_IMAGES_DIR, '*.jpg')) + glob(os.path.join(AUG_IMAGES_DIR, '*.png')))\n",
    "random.shuffle(all_images)\n",
    "\n",
    "n_total = len(all_images)\n",
    "n_train = int(SPLIT_RATIOS['train'] * n_total)\n",
    "n_val = int(SPLIT_RATIOS['val'] * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "splits = {\n",
    "    'train': all_images[:n_train],\n",
    "    'val': all_images[n_train:n_train+n_val],\n",
    "    'test': all_images[n_train+n_val:]\n",
    "}\n",
    "\n",
    "for split, files in splits.items():\n",
    "    for img_path in files:\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(AUG_LABELS_DIR, f\"{base}.txt\")\n",
    "        # Zielpfade\n",
    "        out_img = os.path.join(DATASET_ROOT, split, 'images', f\"{base}.jpg\")\n",
    "        out_label = os.path.join(DATASET_ROOT, split, 'labels', f\"{base}.txt\")\n",
    "        # Kopieren\n",
    "        shutil.copy(img_path, out_img)\n",
    "        shutil.copy(label_path, out_label)\n",
    "\n",
    "print(f\"Datensatz gesplittet: {n_train} train, {n_val} val, {n_test} test\")\n",
    "\n",
    "# dataset.yaml erzeugen\n",
    "yaml_dict = {\n",
    "    'train': os.path.abspath(os.path.join(DATASET_ROOT, 'train', 'images')),\n",
    "    'val': os.path.abspath(os.path.join(DATASET_ROOT, 'val', 'images')),\n",
    "    'test': os.path.abspath(os.path.join(DATASET_ROOT, 'test', 'images')),\n",
    "    'nc': len(CLASS_NAMES),\n",
    "    'names': CLASS_NAMES\n",
    "}\n",
    "with open(os.path.join(DATASET_ROOT, 'dataset.yaml'), 'w') as f:\n",
    "    yaml.dump(yaml_dict, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"dataset.yaml erstellt!\")\n",
    "print(f\"Gespeichert in: {os.path.abspath(os.path.join(DATASET_ROOT, 'dataset.yaml'))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
